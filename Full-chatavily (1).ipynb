{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5653edb8-cd28-4349-8f27-f7e0c1dcb561",
   "metadata": {},
   "source": [
    "# Installing and Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22ba87-3f95-41c3-b0af-8cda7767a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tavily-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a13a48-35f3-4280-a9db-94fe784d8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langgraph tavily sentence-transformers faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41121362-d8c6-4e0e-aefd-d9b815fcf6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"transformers==4.31.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366d036-d81d-4353-ad71-081663260f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tokenizers==0.13.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af758f4-4ffc-4538-a6dc-43b76a5dfb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b1e45-f97c-43b1-920c-5d0a27f124da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TAVILY_API_KEY'] = 'Api key'\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae1f8a-2786-4b68-92f4-d616a73b7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea88ae-9483-4baa-abba-c2d02608ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install transformers[sentencepiece,torch]\n",
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365dc01a-1c75-4124-81b0-8e4a8eef1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ecfb66-d940-4f98-af31-be3dd08c443e",
   "metadata": {},
   "source": [
    "## Working of Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d67c1-0093-4cce-83b6-7a0c4543579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Step 1: Pass your Tavily API Key here\n",
    "search_tool = TavilySearchResults(\n",
    "    tavily_api_key=\"Tavily API Key\"  \n",
    ")\n",
    "\n",
    "# Step 2: Write your query\n",
    "query = \"what is news in india?\"\n",
    "\n",
    "# Step 3: Perform the search\n",
    "result = search_tool.invoke({\"query\": query})\n",
    "\n",
    "# Step 4: Print the result\n",
    "print(\"\\nSearch Results:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140ffca-fce3-48a1-bae4-cb0b90aa81a2",
   "metadata": {},
   "source": [
    "## Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c8f31-3f2f-4fa5-969c-88fc99041fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set API Keys\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"TAVILY KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI KEY\"\n",
    "\n",
    "\n",
    "# Initialize Tools\n",
    "search_tool = TavilySearchResults()\n",
    "reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Step 1: Search Function\n",
    "def search_fn(query):\n",
    "    results = search_tool.invoke({\"query\": query})\n",
    "    return results\n",
    "\n",
    "# Step 2: Rerank Function\n",
    "def rerank_fn(query, results):\n",
    "    pairs = [(query, item[\"content\"]) for item in results]\n",
    "    scores = reranker.predict(pairs)\n",
    "    reranked = [item for _, item in sorted(zip(scores, results), key=lambda x: x[0], reverse=True)]\n",
    "    return reranked[:3]  # Top 3 results\n",
    "\n",
    "# Step 3: Format + Tone Control\n",
    "def format_fn(reranked_results):\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Format the following search results into a clean, professional tone. \n",
    "Make it engaging but formal. Summarize the key points clearly.\n",
    "\n",
    "{results}\n",
    "    \"\"\")\n",
    "    formatted = llm.invoke(prompt.format_prompt(results=reranked_results).to_messages())\n",
    "    return formatted.content\n",
    "\n",
    "# Step 4: Critic Agent (Quality Check)\n",
    "def critic_fn(formatted_result):\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Act as a quality critic. Does the following response meet these rules:\n",
    "- Is it clear and professional?\n",
    "- Is it factually consistent?\n",
    "- Is it relevant to the original query?\n",
    "\n",
    "Respond \"PASS\" if all good, otherwise \"FAIL\" with reason.\n",
    "\n",
    "Response:\n",
    "{response}\n",
    "    \"\"\")\n",
    "    critique = llm.invoke(prompt.format_prompt(response=formatted_result).to_messages())\n",
    "    return critique.content\n",
    "\n",
    "# Step 5: Main Logic (without langgraph)\n",
    "def main_logic(query):\n",
    "    search_results = search_fn(query)\n",
    "    reranked = rerank_fn(query, search_results)\n",
    "    formatted = format_fn(reranked)\n",
    "    critique = critic_fn(formatted)\n",
    "\n",
    "    if \"FAIL\" in critique:\n",
    "        print(\" Critic said FAIL. Re-running search...\")\n",
    "        return main_logic(query)\n",
    "    else:\n",
    "        print(\" Critic said PASS. Final result ready!\")\n",
    "        print(formatted)\n",
    "        return formatted \n",
    "\n",
    "# Step 6: Run Everything\n",
    "user_query = input(\"Enter your search query: \")\n",
    "final_result = main_logic(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33373d75-55cc-4a21-a569-e24152e95825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
